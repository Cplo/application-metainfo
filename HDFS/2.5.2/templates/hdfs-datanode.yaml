<#assign
  registryServer=dependencies.REGISTRY.roles['REGISTRY_SERVER'][0].hostname
  registryPort=dependencies.REGISTRY[registryServer]['registry.port']
  >
<#--federation is true-->
<#if service.nameservices?? && service.nameservices?size gt 0>
<#list service.nameservices as ns>
<#--ha is enabled-->
    <#if service[ns]['HDFS_NAMENODE']?size gt 1>
    <#assign
        namenode1hostname=service[ns]['HDFS_NAMENODE'][0].hostname
        namenode2hostname=service[ns]['HDFS_NAMENODE'][1].hostname
        namenode1nodeid=service[ns]['HDFS_NAMENODE'][0].id
        namenode2nodeid=service[ns]['HDFS_NAMENODE'][1].id
    >
    </#if>
    <#if namenode2nodeid gt namenode1nodeid>
        <#assign minhostname=namenode1hostname >
    <#else>
        <#assign minhostname=namenode2hostname >
    </#if>
</#list>
<#else>
<#--federation is false-->
</#if>
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    name: hadoop-hdfs-datanode-${service.sid}
  name: hadoop-hdfs-datanode-${service.sid}
  namespace: default
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  template:
    metadata:
      labels:
        name: hadoop-hdfs-datanode-${service.sid}
    spec:
      containers:
      - args:
        - bootstrap.sh
        - datanode
        env:
        - name: KRB_ENABLE
          value: 'false'
        - name: HADOOP_HA_NAMENODE_SERVICE
          value: ${namenode1hostname},${namenode2hostname}
        - name: HDFS_JOURNAL_NODE_SPEC
          value: valid
        - name: HDFS_HA
          value: 'true'
        - name: SPEC
          value: ${minhostname}
        - name: HADOOP_CONF_DIR
          value: /etc/${service.sid}/conf
        - name: DATA_DIRS
          value: ${service['dfs.datanode.data.dir']?trim}
        - name: HEAP_SIZE
          value: ${service['datanode.memory']?trim}m
        image: ${registryServer}:${registryPort}/jenkins/hdfs
        imagePullPolicy: Always
        name: hadoop-hdfs-datanode-${service.sid}
        # The path mounts on docker
        volumeMounts:
        - mountPath: /etc/${service.sid}/conf
          name: hdfs
        - mountPath: /var/run/hadoop-common
          name: socketdir
        - mountPath: /var/transwarp/logs
          name: log
        - mountPath: /var/run/${service.sid}
          name: hdfssocketdir
<#list service['dfs.datanode.data.dir']?split(",") as datadir>
        - mountPath: ${datadir?trim}
          name: datanodedir${datadir_index}
</#list>
      hostNetwork: true
      # Ensure that a node can have one hdfs-datanode at most
      podConflictSelectors:
      - matchExpressions:
        - key: podConflictName
          operator: "="
          values:
          - "hdfs-datanode"
      # Ensure that only the node labeled "hdfs-datanode" can start a hdfs-datanode role (i.e., a pod)
      nodeSelector:
        hdfs-datanode: "true"
      # The path on real node
      volumes:
      - hostPath:
          path: /var/log/${service.sid}
        name: log
      - hostPath:
          path: /etc/${service.sid}/conf
        name: hdfs
      - hostPath:
          path: /root/docker/common
        name: socketdir
      - hostPath:
          path: /var/run/${service.sid}
        name: hdfssocketdir
<#list service['dfs.datanode.data.dir']?split(",") as datadir>
      - hostPath:
          path: ${datadir?trim}
        name: datanodedir${datadir_index}
</#list>

